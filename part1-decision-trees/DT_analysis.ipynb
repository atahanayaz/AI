{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees - Heart Disease Classification\n",
    "\n",
    "**Students:** Album #103569, #103512  \n",
    "**Dataset:** Heart Disease (Cleveland)  \n",
    "**Source:** UCI Machine Learning Repository  \n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Understanding](#1-data-loading)\n",
    "2. [Exploratory Data Analysis (EDA)](#2-eda)\n",
    "3. [Data Preprocessing](#3-preprocessing)\n",
    "4. [Decision Tree Model](#4-model)\n",
    "5. [Evaluation](#5-evaluation)\n",
    "6. [Visualization](#6-visualization)\n",
    "7. [Conclusions](#7-conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names based on UCI repository documentation\n",
    "column_names = [\n",
    "    'age',           # age in years\n",
    "    'sex',           # sex (1 = male; 0 = female)\n",
    "    'cp',            # chest pain type (1-4)\n",
    "    'trestbps',      # resting blood pressure (mm Hg)\n",
    "    'chol',          # serum cholesterol (mg/dl)\n",
    "    'fbs',           # fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
    "    'restecg',       # resting ECG results (0-2)\n",
    "    'thalach',       # maximum heart rate achieved\n",
    "    'exang',         # exercise induced angina (1 = yes; 0 = no)\n",
    "    'oldpeak',       # ST depression induced by exercise\n",
    "    'slope',         # slope of peak exercise ST segment (1-3)\n",
    "    'ca',            # number of major vessels colored by fluoroscopy (0-3)\n",
    "    'thal',          # thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "    'target'         # diagnosis (0 = no disease; 1,2,3,4 = disease)\n",
    "]\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/heart_disease.csv', names=column_names, na_values='?')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to binary (0 = no disease, 1 = disease)\n",
    "# Original: 0 = no disease, 1-4 = presence of disease\n",
    "df['target'] = (df['target'] > 0).astype(int)\n",
    "\n",
    "print(\"Target distribution after conversion:\")\n",
    "print(df['target'].value_counts())\n",
    "print(f\"\\nClass balance: {df['target'].value_counts(normalize=True)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(missing_df)\n",
    "\n",
    "# Visualize missing values\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(missing_df.index, missing_df['Missing Count'])\n",
    "    plt.title('Missing Values by Feature')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nNo missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"=\"*80)\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "target_counts = df['target'].value_counts()\n",
    "plt.bar(['No Disease', 'Disease'], target_counts.values, color=['green', 'red'], alpha=0.7)\n",
    "plt.title('Target Distribution (Heart Disease)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Diagnosis')\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    plt.text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Class Balance: {target_counts[1]/target_counts[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    axes[idx].hist(df[col].dropna(), bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hide the last subplot if empty\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for numerical features by target\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    df.boxplot(column=col, by='target', ax=axes[idx], patch_artist=True)\n",
    "    axes[idx].set_title(f'{col} by Disease Status')\n",
    "    axes[idx].set_xlabel('Disease (0=No, 1=Yes)')\n",
    "    axes[idx].set_ylabel(col)\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation = df.corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix - Heart Disease Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "target_corr = correlation['target'].sort_values(ascending=False)\n",
    "print(\"Correlation with Target (Heart Disease):\")\n",
    "print(\"=\"*50)\n",
    "print(target_corr)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_corr[1:].plot(kind='barh', color=['red' if x < 0 else 'green' for x in target_corr[1:]])\n",
    "plt.title('Feature Correlation with Heart Disease', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Features')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    # Create crosstab\n",
    "    ct = pd.crosstab(df[col], df['target'], normalize='index') * 100\n",
    "    ct.plot(kind='bar', ax=axes[idx], color=['green', 'red'], alpha=0.7)\n",
    "    axes[idx].set_title(f'{col} vs Disease', fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Percentage')\n",
    "    axes[idx].legend(['No Disease', 'Disease'])\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (drop rows with missing values)\n",
    "df_clean = df.dropna()\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "print(f\"Clean dataset size: {len(df_clean)}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_clean.drop('target', axis=1)\n",
    "y = df_clean['target']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"\\nFeature names:\")\n",
    "print(list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n",
    "print(\"\\nTraining set target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nTesting set target distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree with max_depth=3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree Model trained successfully!\")\n",
    "print(f\"Tree depth: {clf.get_depth()}\")\n",
    "print(f\"Number of leaves: {clf.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['No Disease', 'Disease'],\n",
    "            yticklabels=['No Disease', 'Disease'])\n",
    "plt.title('Confusion Matrix - Heart Disease Prediction', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['No Disease', 'Disease']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(\"=\"*50)\n",
    "print(feature_importance)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance in Decision Tree', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Testing Different max_depth Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different max_depth values to avoid overfitting\n",
    "depths = range(1, 11)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for depth in depths:\n",
    "    clf_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    clf_temp.fit(X_train, y_train)\n",
    "    \n",
    "    train_scores.append(clf_temp.score(X_train, y_train))\n",
    "    test_scores.append(clf_temp.score(X_test, y_test))\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depths, train_scores, marker='o', label='Training Accuracy', linewidth=2)\n",
    "plt.plot(depths, test_scores, marker='s', label='Testing Accuracy', linewidth=2)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance vs Tree Depth', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best depth\n",
    "best_depth = depths[np.argmax(test_scores)]\n",
    "print(f\"\\nBest max_depth: {best_depth}\")\n",
    "print(f\"Best test accuracy: {max(test_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "tree.plot_tree(clf, \n",
    "               feature_names=X.columns,\n",
    "               class_names=['No Disease', 'Disease'],\n",
    "               filled=True,\n",
    "               rounded=True,\n",
    "               fontsize=10)\n",
    "plt.title('Decision Tree for Heart Disease Classification', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('tree_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Tree visualization saved as 'tree_visualization.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Export tree structure as text\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "tree_rules = export_text(clf, feature_names=list(X.columns))\n",
    "print(\"Decision Tree Rules:\")\n",
    "print(\"=\"*60)\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "\n",
    "1. **Dataset Overview:**\n",
    "   - 303 samples with 13 features\n",
    "   - Binary classification: heart disease presence (yes/no)\n",
    "   - Relatively balanced classes\n",
    "\n",
    "2. **EDA Insights:**\n",
    "   - Strong correlations found between certain features and target\n",
    "   - Most important features: cp (chest pain), thalach (max heart rate), ca (vessels colored)\n",
    "   - Some missing values handled by removal\n",
    "\n",
    "3. **Model Performance:**\n",
    "   - Decision Tree with max_depth=3 achieves good accuracy\n",
    "   - No significant overfitting observed\n",
    "   - Feature importance analysis reveals key predictors\n",
    "\n",
    "4. **Recommendations:**\n",
    "   - Consider ensemble methods for improved performance\n",
    "   - Feature engineering could enhance predictions\n",
    "   - Cross-validation for more robust evaluation\n",
    "\n",
    "### Next Steps:\n",
    "- Tune hyperparameters for optimal performance\n",
    "- Try different algorithms (Random Forest, SVM, etc.)\n",
    "- Collect more data to improve generalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
